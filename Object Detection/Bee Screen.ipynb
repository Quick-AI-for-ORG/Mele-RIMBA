{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pyautogui\n",
    "from tensorflow import keras \n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Load your YOLO model\n",
    "yolo_path = 'Yolos/Insects/train41/weights/best.pt'  \n",
    "bee_path = '../Classifiers/classifiers/beeOrNot.keras'\n",
    "wasp_path = '../Classifiers/classifiers/waspOrNot.keras'\n",
    "yolo_model = YOLO('yolov10n.pt')\n",
    "bee_model = keras.models.load_model(bee_path)\n",
    "wasp_model = keras.models.load_model(wasp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the detection threshold\n",
    "threshold = 0.2\n",
    "input_size = (224,224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get screen dimensions\n",
    "screen_width, screen_height = pyautogui.size()\n",
    "\n",
    "# Define region for screen capture (full screen)\n",
    "region = (0, 0, screen_width, screen_height)\n",
    "\n",
    "# Create an OpenCV window\n",
    "window_name = \"YOLO Detection with Custom Classification\"\n",
    "cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(window_name, 800, 600)\n",
    "\n",
    "while True:\n",
    "    # Capture the screen\n",
    "    screenshot = pyautogui.screenshot(region=region)\n",
    "\n",
    "    # Convert screenshot to a NumPy array (PIL to NumPy)\n",
    "    frame = np.array(screenshot)\n",
    "\n",
    "    # Convert from RGB (PIL format) to BGR (OpenCV format)\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Run YOLO model for object detection\n",
    "    results = yolo_model.predict(source=frame, conf=threshold, verbose=False)\n",
    "\n",
    "    for result in results:\n",
    "        boxes = result.boxes.xyxy.cpu().numpy()  # YOLO bounding boxes\n",
    "        confidences = result.boxes.conf.cpu().numpy()  # YOLO confidence scores\n",
    "\n",
    "\n",
    "        for i, box in enumerate(boxes):\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "\n",
    "            # Clip bounding box coordinates to frame dimensions\n",
    "            x1 = max(0, min(x1, frame.shape[1] - 1))\n",
    "            y1 = max(0, min(y1, frame.shape[0] - 1))\n",
    "            x2 = max(0, min(x2, frame.shape[1] - 1))\n",
    "            y2 = max(0, min(y2, frame.shape[0] - 1))\n",
    "\n",
    "            # Ensure the bounding box is valid\n",
    "            if x2 > x1 and y2 > y1:\n",
    "                # Crop the detected region\n",
    "                cropped_region = frame[y1:y2, x1:x2]\n",
    "                \n",
    "                # Resize the cropped region to match your model's input size\n",
    "                cropped_input = cv2.resize(cropped_region, input_size)\n",
    "                cropped_input = cv2.cvtColor(cropped_input, cv2.COLOR_RGB2BGR)\n",
    "                cropped_input = np.expand_dims(cropped_input, axis=0)  # Add batch dimension\n",
    "                # Run classification using your custom model\n",
    "                predictions = bee_model.predict(cropped_input, verbose=False)\n",
    "                predicted_class = \"Bee\"\n",
    "                confidence_score = np.max(predictions)\n",
    "                if confidence_score < 0.7:\n",
    "                    predictions = wasp_model.predict(cropped_input, verbose=False)\n",
    "                    predicted_class = \"Wasp\"\n",
    "                    confidence_score = np.max(predictions)\n",
    "                    if confidence_score < 0.7:\n",
    "                        predicted_class = \"Other\"\n",
    "                        confidence_score = 1.0 - confidence_score\n",
    "                    \n",
    "                    \n",
    "\n",
    "                # Draw bounding box and label\n",
    "                label = f\"Class {predicted_class} ({confidence_score:.2f})\"\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)  # Draw rectangle\n",
    "                cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)  # Add label\n",
    "\n",
    "    # Display the frame with detections and classifications\n",
    "    cv2.imshow(window_name, frame)\n",
    "\n",
    "    # Exit when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
