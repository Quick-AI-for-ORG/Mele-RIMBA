{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\" style=\"font-family:'Georgia'; font-weight:bold;padding:2%; font-size:50px\">Bees, Wasps or Other Insects</h1>\n",
    "<hr>\n",
    "<h1 style=\"font-family:'Georgia'; font-weight:bold;padding:1%\">Imports</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PIL\n",
    "import cv2\n",
    "import math\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, \\\n",
    "recall_score, f1_score, confusion_matrix, roc_auc_score, roc_curve, \\\n",
    "classification_report, log_loss ,precision_recall_curve, balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "source": [
    "<h1 style=\"font-family:'Georgia'; font-weight:bold;padding:1%\">Constants and Global Variables</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '../Datasets/On Door/'\n",
    "IMAGE_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "SAMPLE_RATE = 22050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'buzzingDetection':layers.SimpleRNN, \n",
    "    'insectDetection': None, \n",
    "    'beeOrNot': None, \n",
    "    'waspOrNot': None, \n",
    "    'decisionMaking': None\n",
    "    }\n",
    "datasets = ['BuzzOrNot', 'BeeOrNot', 'WaspOrNot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-family:'Georgia'; font-weight:bold;padding:1%\">Evaluation</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateModel(yTrue, yPred, yProb=None):\n",
    "    accuracy = accuracy_score(yTrue, yPred)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    balancedAcc = balanced_accuracy_score(yTrue, yPred)\n",
    "    print(f\"Balanced Accuracy: {balancedAcc:.4f}\")\n",
    "    \n",
    "    precision = precision_score(yTrue, yPred)\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    \n",
    "    recall = recall_score(yTrue, yPred)\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    \n",
    "    f1 = f1_score(yTrue, yPred)\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    \n",
    "    cm = confusion_matrix(yTrue, yPred)\n",
    "    print(f\"Confusion Matrix:\\n{cm}\")\n",
    "    \n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "\n",
    "    if yProb is not None:\n",
    "        rocAuc = roc_auc_score(yTrue, yProb)\n",
    "        print(f\"ROC AUC Score: {rocAuc:.4f}\")\n",
    "        \n",
    "        fpr, tpr, _ = roc_curve(yTrue, yProb)\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        plt.plot(fpr, tpr, label=f\"ROC Curve (AUC = {rocAuc:.4f})\")\n",
    "        plt.plot([0, 1], [0, 1], 'k--', label=\"Random Guess\")\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate (Recall)\")\n",
    "        plt.title(\"ROC Curve\")\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "        \n",
    "        precisionCurve, recallCurve, _ = precision_recall_curve(yTrue, yProb)\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        plt.plot(recallCurve, precisionCurve, label=\"Precision-Recall Curve\")\n",
    "        plt.xlabel(\"Recall\")\n",
    "        plt.ylabel(\"Precision\")\n",
    "        plt.title(\"Precision-Recall Curve\")\n",
    "        plt.legend(loc=\"lower left\")\n",
    "        plt.show()\n",
    "\n",
    "    if yProb is not None:\n",
    "        logloss = log_loss(yTrue, yProb)\n",
    "        print(f\"Log Loss: {logloss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\" style=\"font-family:'Georgia'; font-weight:bold;padding:1%\">Buzz Detection (Sound Classification)</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"font-family:'Georgia'; font-weight:bold;padding:1%\">Audio Segmentation</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadAudio(sub='/train'):\n",
    "    print(f\"\\nLoading audio data from {DATASET_PATH + datasets[0] + sub}...\")\n",
    "    PATH = DATASET_PATH + datasets[0] + sub\n",
    "    segments = []\n",
    "    targets = []\n",
    "    \n",
    "    for filename in os.listdir(PATH):\n",
    "        if filename.endswith('.wav'):\n",
    "            audio = os.path.join(PATH, filename)\n",
    "            label = filename.split('.')[0].split('_')[0]\n",
    "            try:\n",
    "                audio, sampleRate = librosa.load(audio)\n",
    "                segments.append(audio)\n",
    "                targets.append('Buzzing' if filename.startswith( 'Bee') else 'No Buzzing')\n",
    "            except:\n",
    "                os.remove(audio)\n",
    "  \n",
    "    return segments, np.array(targets)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"font-family:'Georgia'; font-weight:bold;padding:1%\">Audio Pre-Proccessing</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractMFCC(segments, n_mfcc=12):\n",
    "    print(f\"\\nPadded MFCC extraction for {len(segments)} segments...\")\n",
    "    mfccs = []\n",
    "    mfccs = [librosa.feature.mfcc(y=segment, sr=SAMPLE_RATE, n_mfcc=n_mfcc) for segment in segments]\n",
    "    return mfccs, max([mfcc.shape[1] for mfcc in mfccs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(mfccs, maxLength):\n",
    "    features = [\n",
    "        np.pad(mfcc, ((0, 0), (0, maxLength - mfcc.shape[1])), mode='constant') \n",
    "        for mfcc in mfccs\n",
    "    ]\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\" style=\"font-family:'Georgia'; font-weight:bold;padding:1%\">Bee Detection (Image Classification)</h1>\n",
    "<hr>\n",
    "<h2 style=\"font-family:'Georgia'; font-weight:bold;padding:1%\">Image Pre-Proccessing</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImages(index, sub='/train'):\n",
    "    print(f\"\\nLoading image data from {DATASET_PATH + datasets[index] + sub}...\")\n",
    "    PATH = DATASET_PATH + datasets[1] + sub\n",
    "    subDirs = [d for d in os.listdir(PATH) if os.path.isdir(os.path.join(PATH, d))]\n",
    "    targets = []\n",
    "    images = []\n",
    "    for target in subDirs:\n",
    "        targetPath = os.path.join(PATH, target)\n",
    "        \n",
    "        for filename in os.listdir(targetPath):\n",
    "            \n",
    "            if filename.endswith(('.jpg', '.png')): \n",
    "                image = os.path.join(targetPath, filename)\n",
    "                img = cv2.imread(image)\n",
    "                img = cv2.resize(img, IMAGE_SIZE) \n",
    "                targets.append(target)\n",
    "                images.append(img)\n",
    "                  \n",
    "    return images, np.array(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imagePipeline(index):\n",
    "    xTrain, yTrain = loadImages(index, '/train/')\n",
    "    xTest, yTest = loadImages(index, '/test/')\n",
    "    xTrain, xVal, yTrain, yVal = train_test_split(xTrain, yTrain, test_size=0.2, random_state=42)\n",
    "    return xTrain, yTrain, xVal, yVal, xTest, yTest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-family:'Georgia'; font-weight:bold;padding:1%\">Model Building</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildModel(shape, modelType):  \n",
    "        print(f\"\\nBuilding {modelType.__name__} with input shape {shape}...\")\n",
    "        model = Sequential()\n",
    "        model.add(layers.Input(shape=shape))\n",
    "        \n",
    "        model.add(modelType(128, return_sequences=True))\n",
    "        model.add(modelType(64))\n",
    "        #model.add(layers.Dense(64, activation='tanh'))\n",
    "\n",
    "        \n",
    "        model.add(layers.Dense(1, activation='sigmoid'))\n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, xTrain, yTrain, xVal, yVal):\n",
    "    print(f\"\\nTraining {model.layers[0].__class__.__name__} model...\")\n",
    "    model.fit(xTrain, yTrain, validation_data=(xVal, yVal), epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=0)\n",
    "    predictions = model.predict(xVal)\n",
    "    predictions = np.array([1 if pred > 0.5 else 0 for pred in predictions])\n",
    "    evaluateModel(yVal, predictions)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, xTest, yTest):\n",
    "    predictions = model.predict(xTest)\n",
    "    predictions = np.array([1 if pred > 0.5 else 0 for pred in predictions])\n",
    "    evaluateModel(yTest, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audioPipeline():\n",
    "    xTrain, yTrain = loadAudio('/train/')\n",
    "    xTest, yTest = loadAudio('/test/')\n",
    "    xTrain, maxTrainLength = extractMFCC(xTrain)\n",
    "    xTest, maxTestLength = extractMFCC(xTest)\n",
    "    xTrain = pad(xTrain, max(maxTrainLength, maxTestLength))\n",
    "    xTest = pad(xTest, max(maxTrainLength, maxTestLength))\n",
    "    yTrain = np.array([1 if label == 'Buzzing' else 0 for label in yTrain])\n",
    "    yTest = np.array([1 if label == 'Buzzing' else 0 for label in yTest])\n",
    "    xTrain, xVal, yTrain, yVal = train_test_split(xTrain, yTrain, test_size=0.2, random_state=42)\n",
    "    return xTrain, yTrain, xVal, yVal, xTest, yTest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\" style=\"font-family:'Georgia'; font-weight:bold;padding:2%\">Main</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compareAudioModels(): \n",
    "    xTrain, yTrain, xVal, yVal, xTest, yTest = audioPipeline()\n",
    "    models = [layers.LSTM, layers.GRU, layers.SimpleRNN]\n",
    "    for model in models:\n",
    "        model = buildModel(xTrain.shape[1:], model)\n",
    "        model = train(model, xTrain, yTrain, xVal, yVal)\n",
    "        test(model, xTest, yTest)\n",
    "        \n",
    "# compareAudioModels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading image data from ../Datasets/On Door/BeeOrNot/train/...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[112], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m xTrain, yTrain, xVal, yVal, xTest, yTest \u001b[38;5;241m=\u001b[39m \u001b[43mimagePipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[106], line 2\u001b[0m, in \u001b[0;36mimagePipeline\u001b[1;34m(index)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimagePipeline\u001b[39m(index):\n\u001b[1;32m----> 2\u001b[0m     xTrain, yTrain \u001b[38;5;241m=\u001b[39m \u001b[43mloadImages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/train/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     xTest, yTest \u001b[38;5;241m=\u001b[39m loadImages(index, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/test/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m     xTrain, xVal, yTrain, yVal \u001b[38;5;241m=\u001b[39m train_test_split(xTrain, yTrain, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "Cell \u001b[1;32mIn[105], line 23\u001b[0m, in \u001b[0;36mloadImages\u001b[1;34m(index, sub)\u001b[0m\n\u001b[0;32m     20\u001b[0m nvPath \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(targetPath, nv)  \n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(nvPath):\n\u001b[1;32m---> 23\u001b[0m     nvImg \u001b[38;5;241m=\u001b[39m \u001b[43mnvConvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[0;32m     24\u001b[0m     nvImg \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(nvImg, IMAGE_SIZE)  \n\u001b[0;32m     25\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mimwrite(nvPath, nvImg)\n",
      "Cell \u001b[1;32mIn[104], line 11\u001b[0m, in \u001b[0;36mnvConvert\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m      9\u001b[0m nightVisionImg \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mconvertScaleAbs(nightVisionImg, alpha\u001b[38;5;241m=\u001b[39mALPHA, beta\u001b[38;5;241m=\u001b[39mBETA)\n\u001b[0;32m     10\u001b[0m noise \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m25\u001b[39m, nightVisionImg\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint8)\n\u001b[1;32m---> 11\u001b[0m noisyImg \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnightVisionImg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m blurredImg \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mGaussianBlur(noisyImg, (\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m5\u001b[39m), \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     13\u001b[0m kernel \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m     14\u001b[0m                    [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m     15\u001b[0m                    [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m]])\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "xTrain, yTrain, xVal, yVal, xTest, yTest = imagePipeline(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
